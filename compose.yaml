# volumes:
#   ollama:

x-common: &common
  restart: always
  init: true
  tty: true

x-gpu: &gpu
  environment:
    CUDA_DEVICE_ORDER: PCI_BUS_ID
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            device_ids: ['0']
            capabilities: [gpu, compute]

services:
  ollama:
    <<: [*common, *gpu]
    image: ollama/ollama:0.11.11
    environment:
      OLLAMA_HOST: ${HOST}:${PORT}
      OLLAMA_CONTEXT_LENGTH: ${CONTEXT_LENGTH}
      OLLAMA_KEEP_ALIVE: ${KEEP_ALIVE}
      OLLAMA_MAX_LOADED_MODELS: ${MAX_LOADED_MODELS}
      OLLAMA_NUM_PARALLEL: ${NUM_PARALLEL}
      OLLAMA_FLASH_ATTENTION: ${FLASH_ATTENTION}
    ports:
      - ${PORT}:${PORT}
    volumes:
      - ./data:/root/.ollama
      # - ollama:/root/.ollama
